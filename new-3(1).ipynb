{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"modelInstanceVersion","sourceId":5112,"databundleVersionId":6745013,"modelInstanceId":3900},{"sourceType":"modelInstanceVersion","sourceId":5111,"databundleVersionId":6744792,"modelInstanceId":3899}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install evaluate\n%pip install bitsandbytes\n%pip install peft\n%pip install -U transformers accelerate\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n%pip install -U transformers accelerate\n!pip install --force-reinstall --no-deps markupsafe==2.1.5\n!pip install transformers\n!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:15:33.388961Z","iopub.execute_input":"2024-12-08T21:15:33.389385Z","iopub.status.idle":"2024-12-08T21:16:57.450495Z","shell.execute_reply.started":"2024-12-08T21:15:33.389343Z","shell.execute_reply":"2024-12-08T21:16:57.449440Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nNote: you may need to restart the kernel to use updated packages.\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.25.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.14.0\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting transformers\n  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nCollecting accelerate\n  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.3/336.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, accelerate, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.20.0\n    Uninstalling tokenizers-0.20.0:\n      Successfully uninstalled tokenizers-0.20.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\nSuccessfully installed accelerate-1.2.0 tokenizers-0.21.0 transformers-4.47.0\nNote: you may need to restart the kernel to use updated packages.\nLooking in indexes: https://download.pytorch.org/whl/cu117\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.47.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\nCollecting markupsafe==2.1.5\n  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nInstalling collected packages: markupsafe\n  Attempting uninstall: markupsafe\n    Found existing installation: MarkupSafe 2.1.5\n    Uninstalling MarkupSafe-2.1.5:\n      Successfully uninstalled MarkupSafe-2.1.5\nSuccessfully installed markupsafe-2.1.5\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.47.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nimport wandb\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    Trainer,\n    TrainingArguments,\n)\nfrom peft import LoraConfig, get_peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:16:57.452322Z","iopub.execute_input":"2024-12-08T21:16:57.452607Z","iopub.status.idle":"2024-12-08T21:17:15.943847Z","shell.execute_reply.started":"2024-12-08T21:16:57.452581Z","shell.execute_reply":"2024-12-08T21:17:15.943176Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import sys\nimport json\nimport evaluate\nimport math\nimport torch\nimport torch.nn as nn\nimport bitsandbytes as bnb\nfrom transformers import BitsAndBytesConfig, LlamaForCausalLM, LlamaTokenizer\nfrom peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, get_peft_model_state_dict\nfrom datasets import load_dataset, DatasetDict\nimport transformers\nfrom kaggle_secrets import UserSecretsClient\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:17:15.944945Z","iopub.execute_input":"2024-12-08T21:17:15.945528Z","iopub.status.idle":"2024-12-08T21:17:16.097791Z","shell.execute_reply.started":"2024-12-08T21:17:15.945498Z","shell.execute_reply":"2024-12-08T21:17:16.097137Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Hugging Face authentication\nlogin(token=\"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\")  # Replace with your Hugging Face token\n\n# W&B authentication\nuser_secrets = UserSecretsClient()\nwandb_key = user_secrets.get_secret(\"wandb-key_2\")\nwandb.login(key=wandb_key)\n\n# Initialize W&B project\nwandb.init(project=\"mistral-peft-training\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:17:16.099639Z","iopub.execute_input":"2024-12-08T21:17:16.099905Z","iopub.status.idle":"2024-12-08T21:17:21.853054Z","shell.execute_reply.started":"2024-12-08T21:17:16.099879Z","shell.execute_reply":"2024-12-08T21:17:21.852253Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msriksven\u001b[0m (\u001b[33msriksven-northeastern-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111303548888903, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287c0d46b0d24603a140c6b7a6a05c3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241208_211718-g4ot3s6u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sriksven-northeastern-university/mistral-peft-training/runs/g4ot3s6u' target=\"_blank\">curious-night-33</a></strong> to <a href='https://wandb.ai/sriksven-northeastern-university/mistral-peft-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sriksven-northeastern-university/mistral-peft-training' target=\"_blank\">https://wandb.ai/sriksven-northeastern-university/mistral-peft-training</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sriksven-northeastern-university/mistral-peft-training/runs/g4ot3s6u' target=\"_blank\">https://wandb.ai/sriksven-northeastern-university/mistral-peft-training/runs/g4ot3s6u</a>"},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sriksven-northeastern-university/mistral-peft-training/runs/g4ot3s6u?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7d57e41039d0>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# DDP setting\ndevice_map = 'auto'\nworld_size = int(os.environ.get('WORLD_SIZE', 1))\nddp = (world_size != 1)  # If more than one GPU, then DDP\nif ddp:\n    device_map = {'': int(os.environ.get('LOCAL_RANK') or 0)}\n    GRADIENT_ACCUMULATION_STEPS = GRADIENT_ACCUMULATION_STEPS // world_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:17:21.854153Z","iopub.execute_input":"2024-12-08T21:17:21.854473Z","iopub.status.idle":"2024-12-08T21:17:21.859541Z","shell.execute_reply.started":"2024-12-08T21:17:21.854445Z","shell.execute_reply":"2024-12-08T21:17:21.858667Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_8bit=True,\n#     bnb_4bit_compute_dtype=torch.bfloat16,\n#     bnb_4bit_use_double_quant=True,\n)\n\n\n# Load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\", add_eos_token=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\", quantization_config=quantization_config,   # 8-bit to save VRAM\n    device_map=device_map)\ntokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\nmodel = prepare_model_for_kbit_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:17:21.860600Z","iopub.execute_input":"2024-12-08T21:17:21.860934Z","iopub.status.idle":"2024-12-08T21:23:56.646772Z","shell.execute_reply.started":"2024-12-08T21:17:21.860900Z","shell.execute_reply":"2024-12-08T21:23:56.645897Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19c0172a407c4ac7bfe7d3976b9a3a7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ebd48d7428848aebc3134f0f3a973bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0483a761f87d49008bc14e0b19822d59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96330dd02632481d83f967adaf54ae8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41078319fd1a4a6ca63db392fe31c6bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f0e0f770aa04973850fb5b9231dd49a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d6c94a307b44d0b5ece10450c2f168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41eaa9a73cb344f38e41b085202f59d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e72d4261914418d97e081abcf33163e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"376b6f1ee7704d26841e84622d580139"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7f6e7f412fb409bbb007ca2358c65c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e83f8d651c643a5b8d8bd720d558b01"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"RANDOM_SEED = 1234\ntransformers.set_seed(RANDOM_SEED)\n\n# Fit into Kaggle T4*2\nMICRO_BATCH_SIZE = 4\nBATCH_SIZE = 128\nGRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\nEPOCHS = 1  # One epoch takes ~6 hours, and 2 epochs may exceed Kaggle 12-hour limit \nLEARNING_RATE = 2e-5  # Following stanford_alpaca\nCUTOFF_LEN = 256  # 256 accounts for about 96% of the data. Shorter input, faster training/less VRAM\nLORA_R = 8  # Some LoRA parameters\nLORA_ALPHA = 16\nLORA_DROPOUT = 0.05\nVAL_SET_SIZE = 0\nTARGET_MODULES = [\n    'q_proj',\n    'v_prol',\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:23:56.647749Z","iopub.execute_input":"2024-12-08T21:23:56.647998Z","iopub.status.idle":"2024-12-08T21:23:56.660548Z","shell.execute_reply.started":"2024-12-08T21:23:56.647973Z","shell.execute_reply":"2024-12-08T21:23:56.659889Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"data = load_dataset('kunchum/capstone_1')\n# data = load_dataset('json', data_files='/kaggle/input/qa-data-1/qa_df.json')\ndata = data.shuffle(seed=RANDOM_SEED)  # Shuffle dataset here\n\n# Select a sample of 5000 records for fine-tuning\nsample_size = 20000\ndata_sample = data['train'].select(range(sample_size))\n\n# Create a DatasetDict with the sampled data\nfrom datasets import DatasetDict\n\n# Create a new DatasetDict to retain the original structure\nsampled_data_dict = DatasetDict({\n    'train': data_sample  # You can add validation or test splits if needed\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:23:56.661453Z","iopub.execute_input":"2024-12-08T21:23:56.661683Z","iopub.status.idle":"2024-12-08T21:24:03.078091Z","shell.execute_reply.started":"2024-12-08T21:23:56.661659Z","shell.execute_reply":"2024-12-08T21:24:03.077370Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"qa_data.json:   0%|          | 0.00/70.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85e4d3ae55914b8393a8fa2a49ef9e9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/36612 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af00575e26954523a6a041d0b1a028a4"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def generate_prompt(data_point):\n    \"\"\"Gen. input text based on a prompt, task instruction, (context info.), and answer\n\n    :param data_point: dict: Data point\n    :return: str: Input text\n    \"\"\"\n    # Samples with additional context into.\n    if data_point['context_cleaned'] != \"\":\n        text = 'Below is an instruction that describes a task, paired with an input that provides' \\\n               ' further context. Write a response that appropriately completes the request.\\n\\n'\n        text += f'### Instruction:\\n{data_point[\"instruction\"]}\\n\\n'\n        text += f'### Input:\\n{data_point[\"context_cleaned\"]}\\n\\n'\n        text += f'### Response:\\n{data_point[\"response_cleaned\"]}'\n        return text\n\n    # Without\n    else:\n        text = 'Below is an instruction that describes a task. Write a response that ' \\\n               'appropriately completes the request.\\n\\n'\n        text += f'### Instruction:\\n{data_point[\"instruction\"]}\\n\\n'\n        text += f'### Response:\\n{data_point[\"response_cleaned\"]}'\n        return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:03.079097Z","iopub.execute_input":"2024-12-08T21:24:03.079373Z","iopub.status.idle":"2024-12-08T21:24:03.084972Z","shell.execute_reply.started":"2024-12-08T21:24:03.079345Z","shell.execute_reply":"2024-12-08T21:24:03.084093Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def tokenize(prompt):\n    \"\"\"Tokenise the input\n\n    :param prompt: str: Input text\n    :return: dict: {'tokenised input text': list, 'mask': list}\n    \"\"\"\n    result = tokenizer(prompt, truncation=True, max_length=CUTOFF_LEN + 1, padding='max_length')\n    return {\n        'input_ids': result['input_ids'][:-1],\n        'attention_mask': result['attention_mask'][:-1],\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:03.087659Z","iopub.execute_input":"2024-12-08T21:24:03.087907Z","iopub.status.idle":"2024-12-08T21:24:03.100140Z","shell.execute_reply.started":"2024-12-08T21:24:03.087883Z","shell.execute_reply":"2024-12-08T21:24:03.099332Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def generate_and_tokenize_prompt(data_point):\n    \"\"\"This function masks out the labels for the input, so that our loss is computed only on the\n    response.\"\"\"\n    if data_point['context_cleaned'] != \"\":\n        user_prompt = 'Below is an instruction that describes a task, paired with an input that ' \\\n                      'provides further context. Write a response that appropriately completes ' \\\n                      'the request.\\n\\n'\n        user_prompt += f'### Instruction:\\n{data_point[\"instruction\"]}\\n\\n'\n        user_prompt += f'### Input:\\n{data_point[\"context_cleaned\"]}\\n\\n'\n        user_prompt += f'### Response:\\n'\n    else:\n        user_prompt = 'Below is an instruction that describes a task. Write a response that ' \\\n                      'appropriately completes the request.'\n        user_prompt += f'### Instruction:\\n{data_point[\"instruction\"]}\\n\\n'\n        user_prompt += f'### Response:\\n'\n\n    # Count the length of prompt tokens\n    len_user_prompt_tokens = len(tokenizer(user_prompt,\n                                           truncation=True,\n                                           max_length=CUTOFF_LEN + 1,\n                                           padding='max_length')['input_ids'])\n    len_user_prompt_tokens -= 1  # Minus 1 (one) for eos token\n\n    # Tokenise the input, both prompt and output\n    full_tokens = tokenizer(\n        user_prompt + data_point['response_cleaned'],\n        truncation=True,\n        max_length=CUTOFF_LEN + 1,\n        padding='max_length',\n    )['input_ids'][:-1]\n    return {\n        'input_ids': full_tokens,\n        'labels': [-100] * len_user_prompt_tokens + full_tokens[len_user_prompt_tokens:],\n        'attention_mask': [1] * (len(full_tokens)),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:03.101423Z","iopub.execute_input":"2024-12-08T21:24:03.102011Z","iopub.status.idle":"2024-12-08T21:24:03.111829Z","shell.execute_reply.started":"2024-12-08T21:24:03.101957Z","shell.execute_reply":"2024-12-08T21:24:03.111162Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"MICRO_BATCH_SIZE = 4\nBATCH_SIZE = 128\nGRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\nEPOCHS = 1  # One epoch takes ~6 hours, and 2 epochs may exceed Kaggle 12-hour limit \nLEARNING_RATE = 2e-5  # Following stanford_alpaca\nCUTOFF_LEN = 256  # 256 accounts for about 96% of the data. Shorter input, faster training/less VRAM\nLORA_R = 8  # Some LoRA parameters\nLORA_ALPHA = 16\nLORA_DROPOUT = 0.05\nVAL_SET_SIZE = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:03.113072Z","iopub.execute_input":"2024-12-08T21:24:03.113492Z","iopub.status.idle":"2024-12-08T21:24:03.125790Z","shell.execute_reply.started":"2024-12-08T21:24:03.113452Z","shell.execute_reply":"2024-12-08T21:24:03.124840Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Train/val split\nif VAL_SET_SIZE > 0:\n    train_val = sampled_data_dict['train'].train_test_split(\n        test_size=VAL_SET_SIZE, shuffle=False, seed=RANDOM_SEED\n    )\n    train_data = train_val['train'].map(generate_and_tokenize_prompt)\n    val_data = train_val['test'].map(generate_and_tokenize_prompt)\nelse:\n    train_data = sampled_data_dict['train'].map(generate_and_tokenize_prompt)\n    val_data = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:03.126971Z","iopub.execute_input":"2024-12-08T21:24:03.127230Z","iopub.status.idle":"2024-12-08T21:24:30.893021Z","shell.execute_reply.started":"2024-12-08T21:24:03.127206Z","shell.execute_reply":"2024-12-08T21:24:30.892210Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb8adcdbfdbb446ba91f5f7c8240b8e9"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"sampled_data_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:30.894399Z","iopub.execute_input":"2024-12-08T21:24:30.894752Z","iopub.status.idle":"2024-12-08T21:24:30.901676Z","shell.execute_reply.started":"2024-12-08T21:24:30.894697Z","shell.execute_reply":"2024-12-08T21:24:30.900643Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'context', 'context_cleaned', 'response', 'response_cleaned', 'tag'],\n        num_rows: 20000\n    })\n})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from transformers import TrainerCallback\nimport math\n\n# Custom callback to log and print perplexity at each logging step\nclass PerplexityCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs and \"loss\" in logs:\n            # Calculate perplexity from the training loss\n            perplexity = math.exp(logs[\"loss\"]) if logs[\"loss\"] < 100 else float(\"inf\")\n            logs[\"perplexity\"] = perplexity  # Update logs dictionary with perplexity\n            print(f\"Step {state.global_step} - Training Loss: {logs['loss']:.4f} - Perplexity: {perplexity:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:30.902659Z","iopub.execute_input":"2024-12-08T21:24:30.902985Z","iopub.status.idle":"2024-12-08T21:24:31.076516Z","shell.execute_reply.started":"2024-12-08T21:24:30.902957Z","shell.execute_reply":"2024-12-08T21:24:31.075747Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import bitsandbytes as bnb\ndef create_optimizer(model):\n    return bnb.optim.Adam8bit(model.parameters(), lr=2e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:31.077648Z","iopub.execute_input":"2024-12-08T21:24:31.078410Z","iopub.status.idle":"2024-12-08T21:24:31.085534Z","shell.execute_reply.started":"2024-12-08T21:24:31.078373Z","shell.execute_reply":"2024-12-08T21:24:31.084833Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\nfrom transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\n# Update the configuration with correct paths\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:31.086478Z","iopub.execute_input":"2024-12-08T21:24:31.086739Z","iopub.status.idle":"2024-12-08T21:24:31.415546Z","shell.execute_reply.started":"2024-12-08T21:24:31.086716Z","shell.execute_reply":"2024-12-08T21:24:31.414707Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model.add_adapter(adapter_name=\"lora_adapter\", peft_config=lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:31.416676Z","iopub.execute_input":"2024-12-08T21:24:31.417005Z","iopub.status.idle":"2024-12-08T21:24:31.679975Z","shell.execute_reply.started":"2024-12-08T21:24:31.416968Z","shell.execute_reply":"2024-12-08T21:24:31.679128Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Use an existing special token for padding if pad_token is not set\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:31.681101Z","iopub.execute_input":"2024-12-08T21:24:31.681410Z","iopub.status.idle":"2024-12-08T21:24:31.686630Z","shell.execute_reply.started":"2024-12-08T21:24:31.681379Z","shell.execute_reply":"2024-12-08T21:24:31.685732Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"trainer = transformers.Trainer(\n    model=model,\n    train_dataset=train_data,\n#     eval_dataset=val_data,\n    args=transformers.TrainingArguments(\n    output_dir='/kaggle/working/mistral_training',  # Directory for saving model outputs and checkpoints\n    num_train_epochs=1,  # Limit epochs to minimize runtime and prevent hitting the time limit\n    per_device_train_batch_size=16,  # Reduced batch size to decrease memory usage\n    gradient_accumulation_steps=1024,  # Increase gradient accumulation to simulate a larger batch size\n    learning_rate=2e-5,  # Appropriate learning rate for fine-tuning\n    logging_dir='/kaggle/working/logs',  # Directory for storing logs\n    logging_steps=100,  # Log metrics every 100 steps\n    do_train=True,  # Enable training\n    do_eval=False,  # Disable evaluation to save time and resources\n    save_strategy=\"no\",  # Disable model checkpoint saving to conserve disk space\n    report_to=\"wandb\",  # Disable reporting to Weights & Biases to prevent overhead unless specifically desired\n    fp16=True,  # Enable mixed precision training to reduce memory usage and potentially speed up training\n    load_best_model_at_end=False,  # Do not load the best model at the end as saving and loading models is disabled\n    save_total_limit=0,  # Limit the number of saved checkpoints (none in this case)\n    evaluation_strategy=\"no\",  # Disable evaluation to focus resources on training only\n    seed=1234,  # Set a fixed seed for reproducibility\n    disable_tqdm=False,  # Enable tqdm progress bars for better visibility of the training progress\n    push_to_hub=False# Disable pushing to the Hugging Face Hub to avoid unnecessary overhead\n),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n#     compute_metrics=compute_metrics,\n    callbacks=[PerplexityCallback()]\n)\nmodel.config.use_cache = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:24:31.687832Z","iopub.execute_input":"2024-12-08T21:24:31.688184Z","iopub.status.idle":"2024-12-08T21:24:32.196542Z","shell.execute_reply.started":"2024-12-08T21:24:31.688147Z","shell.execute_reply":"2024-12-08T21:24:32.195627Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}