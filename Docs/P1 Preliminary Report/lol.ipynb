{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPwFrnDmWnoogWWiQfxBiQC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"rqKrQNm2fza3","executionInfo":{"status":"error","timestamp":1728699178333,"user_tz":240,"elapsed":455,"user":{"displayName":"Laasya Anantha Prasad","userId":"13966426256818682754"}},"outputId":"50968dd5-9629-4650-8727-d633f5ccbbb7"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"unmatched ']' (<ipython-input-2-9297da88a7bf>, line 32)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-9297da88a7bf>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    ])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ']'\n"]}],"source":["import re\n","import pandas as pd\n","from transformers import AutoTokenizer\n","from qdrant_client import QdrantClient\n","\n","# Initialize Qdrant client and tokenizer\n","client = QdrantClient(host='localhost')\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Load data\n","data = pd.read_csv(\"financial_news.csv\")\n","\n","# Text normalization function\n","def preprocess_text(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n","    text = text.lower()  # Convert to lowercase\n","    return text\n","\n","# Apply preprocessing\n","data['cleaned_text'] = data['text'].apply(preprocess_text)\n","\n","# Tokenization and embedding\n","data['tokens'] = data['cleaned_text'].apply(tokenizer.tokenize)\n","embeddings = tokenizer(data['cleaned_text'], return_tensors=\"pt\", padding=True, truncation=True)\n","\n","# Store embeddings in Qdrant\n","for idx, embedding in enumerate(embeddings['input_ids']):\n","    client.upload_collection(name=\"finance_advisor\", points=[\n","        {\"id\": idx, \"vector\": embedding.tolist(), \"payload\": {\"text\": data['cleaned_text'][idx]}}\n","    ])\n"]},{"cell_type":"code","source":["pip install qdrant_client"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lIhabsZbgJjz","executionInfo":{"status":"ok","timestamp":1728699255308,"user_tz":240,"elapsed":31409,"user":{"displayName":"Laasya Anantha Prasad","userId":"13966426256818682754"}},"outputId":"62f4dfc2-37bc-4e7f-f6e7-3adb1df873f8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting qdrant_client\n","  Downloading qdrant_client-1.12.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.64.1)\n","Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n","  Downloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n","Collecting httpx>=0.20.0 (from httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.26.4)\n","Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.9.2)\n","Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.2.3)\n","Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant_client)\n","  Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n","Collecting grpcio>=1.41.0 (from qdrant_client)\n","  Downloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (71.0.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2024.8.30)\n","Collecting httpcore==1.* (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (2.23.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (4.12.2)\n","Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n","Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.2.2)\n","Downloading qdrant_client-1.12.0-py3-none-any.whl (266 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.4/266.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Installing collected packages: protobuf, portalocker, hyperframe, hpack, h11, grpcio, httpcore, h2, grpcio-tools, httpx, qdrant_client\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.64.1\n","    Uninstalling grpcio-1.64.1:\n","      Successfully uninstalled grpcio-1.64.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n","google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n","google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n","tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.2 which is incompatible.\n","tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.2 which is incompatible.\n","tensorflow-metadata 1.16.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed grpcio-1.66.2 grpcio-tools-1.66.2 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.6 httpx-0.27.2 hyperframe-6.0.1 portalocker-2.10.1 protobuf-5.28.2 qdrant_client-1.12.0\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n","import loralib as lora  # Hypothetical LoRA library for demonstration\n","\n","# Load base model and modify layers for LoRA adaptation\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","model = lora.lora_model(model, rank=4)  # Applying LoRA with a specified rank\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    logging_dir='./logs',\n","    evaluation_strategy=\"epoch\"\n",")\n","\n","# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=financial_train_dataset,\n","    eval_dataset=financial_eval_dataset\n",")\n","\n","trainer.train()\n"],"metadata":{"id":"E5JMEySNf0Ux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","\n","# Generate word cloud\n","text = \" \".join(review for review in data['cleaned_text'])\n","wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n","\n","# Plot word cloud\n","plt.figure(figsize=(10, 5))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis(\"off\")\n","plt.title(\"Word Cloud of Financial Terms\")\n","plt.show()\n"],"metadata":{"id":"OiX2i-sUiU_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate prompt lengths\n","data['prompt_length'] = data['cleaned_text'].apply(lambda x: len(x.split()))\n","\n","# Plot histogram of prompt lengths\n","plt.figure(figsize=(10, 5))\n","plt.hist(data['prompt_length'], bins=20, color='skyblue', edgecolor='black')\n","plt.title(\"Prompt Length Distribution\")\n","plt.xlabel(\"Prompt Length (words)\")\n","plt.ylabel(\"Frequency\")\n","plt.show()\n"],"metadata":{"id":"mfyq6FxWis7s"},"execution_count":null,"outputs":[]}]}